{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf2Y4ptvAnBx"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets timm lightning albumentations --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlKMGFu8BEcm"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "\n",
        "# Assign the Kaggle data set URL into variable\n",
        "dataset = 'https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data'\n",
        "od.download(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml0Y6xNpBF5v"
      },
      "outputs": [],
      "source": [
        "# custom modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import utilities\n",
        "#import model_functions\n",
        "import model_factory\n",
        "\n",
        "#lightning modules and callbacks\n",
        "import lightning_data\n",
        "import lightning_model\n",
        "import train_info\n",
        "import learning_curves\n",
        "import confusion_matrix\n",
        "\n",
        "import os\n",
        "import copy\n",
        "\n",
        "# timm models\n",
        "import timm\n",
        "\n",
        "# torch modules (temporarily)\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "# pytorch lightning (for checkpointing callbacks)\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import CSVLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcPhYsM5BJse"
      },
      "outputs": [],
      "source": [
        "# necessary, as checkpoints will be saved on GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEXXMbDS0E4G"
      },
      "outputs": [],
      "source": [
        "# ResNet50\n",
        "\n",
        "resnet50_config = {\n",
        "    'model_name': 'resnet50', # name of the pretrained model\n",
        "    'classifier_name': 'linear', # name of the classifier (e.g. linear/nonlinear)\n",
        "    'classifier_type': None, # leave it None\n",
        "    'layers': 'all', # layers to train (e.g. first (starting from last), second (starting from last), all)\n",
        "    'augmentation': 'strong', # augmentation type (e.g. normal or strong)\n",
        "    'classes_weight': None, # weights for each class\n",
        "    'batch_size': 128,\n",
        "    'val_split': 0.1,\n",
        "    'n_epochs': 20,\n",
        "    'optimizer': 'Adam',\n",
        "    'scheduler': '', # leave it empty to not use any scheduling\n",
        "    'ensemble': True,\n",
        "    'image_size': None,\n",
        "    'mean': None,\n",
        "    'std': None\n",
        "    }\n",
        "\n",
        "resnet50_config['classifier_type'] = model_factory.get_linear_classifer if resnet50_config['classifier_name'] == 'linear' else model_factory.get_simple_non_linear_classifier\n",
        "\n",
        "resnet50_ckpt = '/content/drive/MyDrive/models/resnet50/linear all strong Adam /epoch=4-step=180.ckpt'\n",
        "l_resnet50_model = lightning_model.PneumoniaModel.load_from_checkpoint(resnet50_ckpt, h=resnet50_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1niiOyi-0hPI"
      },
      "outputs": [],
      "source": [
        "# DenseNet121\n",
        "\n",
        "densenet121_config = {\n",
        "    'model_name': 'densenet121', # name of the pretrained model\n",
        "    'classifier_name': 'linear', # name of the classifier (e.g. linear/nonlinear)\n",
        "    'classifier_type': None, # leave it None\n",
        "    'layers': 'all', # layers to train (e.g. first (starting from last), second (starting from last), all)\n",
        "    'augmentation': 'strong', # augmentation type (e.g. normal or strong)\n",
        "    'classes_weight': None, # weights for each class\n",
        "    'batch_size': 64,\n",
        "    'val_split': 0.1,\n",
        "    'n_epochs': 20,\n",
        "    'optimizer': 'SGD',\n",
        "    'scheduler': 'CosineAnnealingLR10', # leave it empty to not use any scheduling\n",
        "    'ensemble': True,\n",
        "    'image_size': None,\n",
        "    'mean': None,\n",
        "    'std': None\n",
        "    }\n",
        "\n",
        "densenet121_config['classifier_type'] = model_factory.get_linear_classifer if densenet121_config['classifier_name'] == 'linear' else model_factory.get_simple_non_linear_classifier\n",
        "\n",
        "densenet121_ckpt = '/content/drive/MyDrive/models/densenet121/linear all strong SGD CosineAnnealingLR10/epoch=8-step=639.ckpt'\n",
        "l_densenet121_model = lightning_model.PneumoniaModel.load_from_checkpoint(densenet121_ckpt, h=densenet121_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbEvqskW0j4X"
      },
      "outputs": [],
      "source": [
        "# EfficientNet_b0\n",
        "\n",
        "efficientnet_b0_config = {\n",
        "    'model_name': 'efficientnet_b0', # name of the pretrained model\n",
        "    'classifier_name': 'linear', # name of the classifier (e.g. linear/nonlinear)\n",
        "    'classifier_type': None, # leave it None\n",
        "    'layers': 'all', # layers to train (e.g. first (starting from last), second (starting from last), all)\n",
        "    'augmentation': 'strong', # augmentation type (e.g. normal or strong)\n",
        "    'classes_weight': None, # weights for each class\n",
        "    'batch_size': 64,\n",
        "    'val_split': 0.1,\n",
        "    'n_epochs': 20,\n",
        "    'optimizer': 'SGD',\n",
        "    'scheduler': '', # leave it empty to not use any scheduling\n",
        "    'ensemble': True,\n",
        "    'image_size': None,\n",
        "    'mean': None,\n",
        "    'std': None\n",
        "    }\n",
        "\n",
        "efficientnet_b0_config['classifier_type'] = model_factory.get_linear_classifer if efficientnet_b0_config['classifier_name'] == 'linear' else model_factory.get_simple_non_linear_classifier\n",
        "\n",
        "efficientnet_b0_ckpt = '/content/drive/MyDrive/models/efficientnet_b0/linear all strong SGD /epoch=9-step=710.ckpt'\n",
        "l_efficientnet_b0_model = lightning_model.PneumoniaModel.load_from_checkpoint(efficientnet_b0_ckpt, h=efficientnet_b0_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6RTjGWB61Gu"
      },
      "outputs": [],
      "source": [
        "resnet50_model = copy.deepcopy(l_resnet50_model.model)\n",
        "densenet121_model = copy.deepcopy(l_densenet121_model.model)\n",
        "efficientnet_b0_model = copy.deepcopy(l_efficientnet_b0_model.model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUxMAomNBbsQ"
      },
      "outputs": [],
      "source": [
        "resnet50_model.fc = nn.Sequential(*list(resnet50_model.fc.children())[:-1])\n",
        "densenet121_model.classifier = nn.Sequential(*list(densenet121_model.classifier.children())[:-1])\n",
        "efficientnet_b0_model.classifier = nn.Sequential(*list(efficientnet_b0_model.classifier.children())[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7iDp2-_Cq4y"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "pneumonia_data_resnet50 = lightning_data.PneumoniaDataModule(resnet50_config)\n",
        "pneumonia_data_resnet50.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUc_8PaWG1ZT"
      },
      "outputs": [],
      "source": [
        "test_set = pneumonia_data_resnet50.test_set\n",
        "print(len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHkh2kxfG156"
      },
      "outputs": [],
      "source": [
        "meta_train_set = pneumonia_data_resnet50.meta_set\n",
        "print(len(meta_train_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_DnIGb2CtAC"
      },
      "outputs": [],
      "source": [
        "# Can I do this?\n",
        "'''\n",
        "pneumonia_data.setup()\n",
        "test_set = pneumonia_data.test_set\n",
        "print(len(test_set))\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf2Yhh0bDGNZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def create_meta_data(data_loader, model_list):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    meta_X = []\n",
        "    meta_Y = []\n",
        "\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs = inputs.unsqueeze(0)\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        logits_list = []\n",
        "\n",
        "        for model in model_list:\n",
        "            model.to(device)\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(inputs)\n",
        "\n",
        "            logits_list.append(logits.cpu().numpy())\n",
        "\n",
        "        meta_X.append(np.concatenate(logits_list, axis=1))\n",
        "        meta_Y.append(labels)\n",
        "\n",
        "    meta_X = np.concatenate(meta_X, axis=0)\n",
        "    meta_Y = np.array(meta_Y)\n",
        "\n",
        "    indices = np.arange(meta_X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    meta_X = meta_X[indices]\n",
        "    meta_Y = meta_Y[indices]\n",
        "\n",
        "    return meta_X, meta_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqxmVwcwEHEC"
      },
      "outputs": [],
      "source": [
        "# models = [model1, model2, model3]\n",
        "models = [resnet50_model, densenet121_model, efficientnet_b0_model]\n",
        "\n",
        "X_train, y_train = create_meta_data(meta_train_set, models)\n",
        "X_test, y_test = create_meta_data(test_set, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQwOOMuGGa7z"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNzuh4fRG95I"
      },
      "outputs": [],
      "source": [
        "print(y_train.shape)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg8Q4oGAHonA"
      },
      "outputs": [],
      "source": [
        "print(X_test.shape)\n",
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI2Kr6ptH6bo"
      },
      "outputs": [],
      "source": [
        "print(y_test.shape)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53mrDRROsXHs"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Step 1: Initialize the logistic regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Step 2: Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "print(f\"Precision on the test set: {precision}\")\n",
        "print(f\"Recall on the test set: {recall}\")\n",
        "print(f\"F1 score on the test set: {f1}\")\n",
        "print(f\"AUC on the test set: {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGvkdHfZ8vrL"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Step 1: Initialize the SVM model\n",
        "model = SVC(probability=True)  # Set probability=True to enable probability estimates\n",
        "\n",
        "# Step 2: Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "print(f\"Precision on the test set: {precision}\")\n",
        "print(f\"Recall on the test set: {recall}\")\n",
        "print(f\"F1 score on the test set: {f1}\")\n",
        "print(f\"AUC on the test set: {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVQl2KNQI8_I"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Step 1: Initialize the Decision Tree model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Step 2: Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "print(f\"Precision on the test set: {precision}\")\n",
        "print(f\"Recall on the test set: {recall}\")\n",
        "print(f\"F1 score on the test set: {f1}\")\n",
        "print(f\"AUC on the test set: {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miwOuNXo9BqG"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Step 1: Initialize the MLP classifier model\n",
        "model = MLPClassifier(hidden_layer_sizes=(6,), max_iter=1000)  # One hidden layer with 100 units\n",
        "\n",
        "# Step 2: Train the model on the training set\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Accuracy on the test set: {accuracy}\")\n",
        "print(f\"Precision on the test set: {precision}\")\n",
        "print(f\"Recall on the test set: {recall}\")\n",
        "print(f\"F1 score on the test set: {f1}\")\n",
        "print(f\"AUC on the test set: {auc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
